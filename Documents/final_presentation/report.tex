\documentclass[12pt]{article}

\usepackage{amsfonts,amssymb,amsmath,amsthm}
\usepackage{stmaryrd} %for special brackets
\usepackage{lipsum}
\usepackage{graphicx}
\graphicspath{Images}
\usepackage[hidelinks]{hyperref}
\usepackage{array}
\usepackage{bm} %for bold in math equations
\usepackage{float} %to force the position of some figures
\usepackage{biblatex}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{listings}

\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    commentstyle=\itshape\color{purple!40!black},
    keywordstyle=\bfseries\color{blue!70!black},
    stringstyle=\color{green!60!black},
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    breaklines=true,
    breakatwhitespace=true,
    frame=single,
    rulecolor=\color{black!20},
    backgroundcolor=\color{gray!5},
    tabsize=4,
    captionpos=b
}

\title{Report}
\author{Lucas SALAND}
\date{\today}

\begin{document}
\input{title_page.tex}
\tableofcontents
\todo[inline]{table of figures}
\todo[inline]{table of tables}
\section{Introduction}
Communication is crucial in our civilization. There are many ways to communicate and transmit information nowadays. The rise of information technology in the past decades enabled more communication than ever before in many different forms: images, texts, videos, audios\dots Information is encoded in a specific way for each type of information. And even for a same type of media such as images, there exist different formats in which information can be encoded. What can be done when hidden communication is needed on a transmission channel that other might have access to? A first idea could be to use encryption to hide the meaning of the messsage, the presence of the message is known, its meaning is unknown.  A second idea is to hide the message to be transmitted in another piece of content and transmit it without raising suspicions about the modified piece of content. This is called steganography. The original piece of content is called a cover. Once the hidden message has been embedded, it becomes the stego. Steganography is often paired with steganalysis. The goal of steganalysis is to detect whether a message was hidden in a given piece of content. In this project, we were interested in steganography performed on AI-compressed images.\\
There exists many papers on steganography performed on JPEG images but none explored yet steganography on AI-compressed images. Images can be represented in many different spaces: RGB, DCT (JPEG), YCbCr, HSV/HSL... The first step of steganography on images is to chose on which representation of images we want to embbed the message. AI-compressed images have their own representation.\\
Using deep learning for image compression was first introduced in "End-To-End Optimized Image Compression". This paper developed the idea of using convolutional neural network to obtain a representation of images in a latent space. This representation in latent space is the one on which steganography will be performed. Modern steganalysis on images relies on neural network detectors. In this project, we use SRNet to perform classification of images with classes "stego" and "cover".

\section{AI image compression}
\subsection{Autoencoder and latent space}
The idea behind AI image compression is to have a compact representation of images using deep learning. To do so, we can use an autoencoder. The encoder part is used to obtain a representation of images in latent space. The coefficients of this representation is then quantized. We can then reconstruct a quantized image by feeding the quantized latent representation to the decoder part of the autoencoder. The training is done by optimizing the weighted sum of the rate and distortion.
\begin{figure}[H]
    \centering
    \includegraphics*[width=.6\textwidth]{./img/transform_coding.png}
    \caption[short]{$x$: uncompressed image, $y$: latent representation of $x$, $\hat{y}$: quantized latent representation of $x$, $\hat{x}$ reconstructed image}
\end{figure}
Compressed images obtained with the autoencoder approach are smoother than the ones obtained with JPEG.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./img/jpeg_ai.png}
    \caption[short]{AI compression vs JPEG compression (End To End Image Compression paper)}
\end{figure}

A pytorch implementation of this idea was provided by the iclr\_17\_compression repository available on Github. Nevertheless, no model checkpoint nor training data were provided.


\subsection{Training the model}
The generation of the training data was done using a script provided on the github repository. With this script, 80G of training data are generated. Once the training data has been generated, the training of the model can be started. The model used in all other experiments in this report has been trained over 1590000 steps across 6 epochs. The base models from which all other model in this project are derived from is called ImageCompressor.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{./img/ImageCompressor.png}
    \caption[short]{ImageCompressor model}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/Original_reconstructed.png}
    \caption[short]{Input \& output of ImageCompressor model}
\end{figure}

\section{Steganography}
\subsection{Naive method: LSB replacement}
\subsubsection{Least significant bit replacement}
The least significant bit replacement consists in adding or substracting 1 to quantized coefficients of the latent representation with a given probability. We can model the modification as follows:

\begin{itemize}
    \item $c_i: \text{quantized coefficient in the latent space}$
    \item $\mathcal{E}
    _i \sim Categorical_{\{-1,0,1\}},\\
    \ \mathbb{P}(\mathcal{E}_i = -1) = \mathbb{P}(\mathcal{E}_i = 1) = p,\\
    \mathbb{P}(\mathcal{E}_i = 0) = 1-2p$ 
    \item $\hat{C}_i = c_i + \mathcal{E}_i \sim Categorical_{\{c_i-1,\ c_i,\ c_i+1\}}:$ quantized coefficient after modification
\end{itemize}

For each coeffcient $c_i$ we sample a realization $\epsilon_i$ of $\mathcal{E}_i$ and obtain the modified version of this coefficient $\hat{c_i}$ which is a realization of $\hat{C_i}$.\\
The image reconstructed from the original latent representation is called the \textbf{cover} whereas the one reconstructed from the modified latent representation is called the \textbf{stego}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{./img/naive_insertion.png}
    \caption[short]{diagram of the probabilities of modification of coefficients}
    \label{fig:probabilities}
\end{figure}
The insertion rate is given by $H_3(p) = -2p*log_2(p) - (1-2p)log_2(1-2p)$ in bits per coefficient. The size of the message we embbed is given by \[\text{size = number coefficients in latent space * insertion rate}\]
\subsubsection{Implementation}
The insertion is done on the quantized coefficients in latent space. Thus, a new model ImageCompressorSteganography based on ImageCompressor contains the necessary steps to perform the insertion given a probability p (see \autoref{fig:probabilities}). The first version of the LSB modification was implemented using 3 for-loops. Due to low performances of python for-loops, a new implementation was done using pytorch's multinomial method, enabling computations to be performed 30 times faster by taking advantage of GPU's computational power.

\subsection{Side information: quantization error}
The LSB modification is a very basic approach to perform steganography. Its simplicity makes it easy to detect. Every coeffcient in the latent representation has the same probability of modifications. To make it less detectable, we can use the quantization error: the difference between original coefficients and quantized coefficients in latent space. The goal is to give higher probability of modification where the quantization error is important and smaller probabilities where the quantization error is close to zero.  
\subsubsection{Non-uniform probability of modification}
To obtain different probabilities of modification for each coefficient, an optimization problem under constraint must be solved, the unknown is $\lambda$:

\begin{table}[H]
\begin{tabular}{ |c|c|c| }
    \hline
    &  & Comments\\
    \hline
    & $e_i = \text{coef}_i - \text{quantized\_coef}_i$ & quantization error on the i-th coefficient\\ 
    & $c_{i,-1} = 1 + 2e_i$ & cost of -1 modification\\ 
    Notations & $c_{i,0} = 0$ & no penalization\\
    & $c_{i,1} = 1 - 2e_i$ & cost of +1 modification\\
    & $p_{i,k} = \frac{e^{-\lambda c_{i,k}}}{e^{-\lambda c_{i,-1}} + e^{-\lambda c_{i,0}} + e^{-\lambda c_{i,1}}}$ & probability of +k on coef i, k $\in$ \{-1,0,1\}\\
    & $\lambda$ & variable of the problem\\
    \hline
    Constraint & $\displaystyle\sum_{i=1}^{\# coefs}{H_3(p_{i,-1},p_{i,0},p_{i,1})} = M$ & M: size of the message to insert in bits\\
    \hline
    Objective & $\displaystyle\sum_{i=1}^{\# coefs}{\sum_{k=-1}^{1}{p_{i,k}c_{i,k}}}$ & distorsion to minimize \\ 
    \hline
\end{tabular}
\caption[short]{Optimization problem to solve}
\end{table}
This problem is solved using an iterative algorithm. The code for this algorithm was kindly provided by Patrick Bas. This code only works with 1-D numpy arrays.

\subsubsection{Implementation}
Tensor to np array -> flatten -> cost -> probabilities -> embedding -> reshape -> np array to Tensor 
\todo[inline]{Detail more}
\subsubsection{Modifying the cost}
\todo[inline]{Complete this part}
\section{Steganalysis}
\subsection{JIN SRNet}
JIN SRNet is a deep convolutional neural network whose purpose is to detect if steganography was performed on an image. It is pretrained on ImageNet database. This model can be fine tuned to assess the performances of naive insertion and side information methods. A first idea to compare the 2 methods was to compare the prediction error of JINSRNet on two stego datasets generated with the two methods for the same payload. A second idea is to generate 2 stego datasets with different payload for each method such that the prediction error is the same. 
\subsubsection{Generating cover and stego datasets}
To fine-tune the JINSRNet model, the first step is to generate cover and stego datasets. The original dataset used is BossBase. A dataset of 10 000 grayscaled images saved in pgm format. 
\todo[inline]{Images of BossBase}
The cover dataset is generated by feeding the 10 000 images from BossBase to ImageCompressor, the images are saved as .pt (pytorch tensors). For stego datasets, several where generated for each method. One dataset is generated per payload and per method used. Taking into consideration that Bossbase, cover and one stego dataset take 90GB of space on disk, it was not possible to store many versions of stego datasets at once. Thus, every time a new stego dataset was generated, the previous one was removed in order to save some space.\\
For every method, the generation of the stego dataset is similar. The only difference is which variant of ImageCompressor model is used. The steps are the following:
\begin{itemize}
    \item read pgm files (original images from BossBase)
    \item convert each file into a tensor as ImageCompressor-based models works with tensors
    \item feed the tensor image to the ImageCompressor-based model corresponding to the method we want to use with the correct payload (ImageCompressorSteganography for LSB, ImageCompressorSteganography\_QE for side information and ImageCompressorSteganography\_QE\_modified\_cost for the variant of side information)
    \item save the generated image as a tensor on disk
\end{itemize}

As ImageCompressor-based models were designed to work on RGB images, it takes as input tensors with three color channels. Thus the grayscale channel of pgm images was duplicated on three channels in order to feed them to each model.
\todo[inline]{Talk about img\_saving.ipynb}

\subsubsection{Fine-tuning the pretrained model}
Once the datasets are generated. We can fine-tune JINSRNet.
Training script and pretrained model were kindly provided by Jan Butora. Some adjustment were needed in order to load the training data as the original script loaded jpeg files. The class loading the data is called a retriever. We implemented a retriever that works with .pt files (pytorch tensors). The images saved as pytorch tensors are loaded and converted into numpy arrays. To convert pytorch images into numpy images there is two different methods. The first one consists in using the ToPILImage() function of pytorch which converts a pytorch tensor into a PIL image which we can then convert into a numpy array. The second method consists in permuting axis of the tensor to fit numpy convention for representation of images and then converting the tensor into a numpy array by using numpy() function of pytorch Tensor class. As we can see on \autoref{tab:torch2np}, the method of permuting axis and converting to NumPy using numpy() function is about 10 times faster than the other method. Thus this method is the one used for tensor to numpy array conversion.\\

\begin{lstlisting}[caption={Conversion of pytorch tensors into numpy images}, label={lst:example}]
to_pil = ToPILImage()
# bad performance
img_numpy = np.array(to_pil(img_pytorch[0]))

# good performance
img_numpy = img_pytorch[0].permute(1,2,0).cpu().numpy() 
\end{lstlisting}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        ToPIL & numpy()\\
        \hline
        $5.15\ ms\ \pm\ 238 \mu s$  & $523 \mu s\ \pm\ 18.7 \mu s  $\\
        \hline
    \end{tabular}
    \caption[short]{Performances comparison of tensor to numpy conversion}
    \label{tab:torch2np}
\end{table}

\begin{table}[H]
    \centering
\begin{tabular}{|c|c|c|}
    \hline
    Axis & Pytorch & Numpy \\
    \hline
    0 & batch dimension & height \\
    \hline
    1 & channel & width\\
    \hline
    2 & height & channel\\
    \hline
    3 & width & $\emptyset$\\
    \hline
\end{tabular}    
\caption[short]{Difference of image representation between NumPy and Pytorch}
\end{table}


\subsection{Results}
\subsubsection{Naive insertion}
\subsubsection{Side information}
\subsubsection{Modified cost}

\section{Conclusion}

\section*{References}
\end{document}