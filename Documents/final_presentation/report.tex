\documentclass[12pt]{article}

\usepackage{amsfonts,amssymb,amsmath,amsthm}
\usepackage{stmaryrd} %for special brackets
\usepackage{lipsum}
\usepackage{graphicx}
\graphicspath{Images}
\usepackage[hidelinks]{hyperref}
\usepackage{array}
\usepackage{bm} %for bold in math equations
\usepackage{float} %to force the position of some figures
\usepackage{biblatex}
\usepackage[colorinlistoftodos]{todonotes}
\usepackage{multirow}
\usepackage{multicol}
\usepackage{listings}
\usepackage[ruled, lined, linesnumbered, commentsnumbered, longend]{algorithm2e}
\usepackage{biblatex}
\addbibresource{RP.bib}


\lstset{
    language=Python,
    basicstyle=\ttfamily\small,
    commentstyle=\itshape\color{purple!40!black},
    keywordstyle=\bfseries\color{blue!70!black},
    stringstyle=\color{green!60!black},
    showstringspaces=false,
    numbers=left,
    numberstyle=\tiny,
    numbersep=5pt,
    breaklines=true,
    breakatwhitespace=true,
    frame=single,
    rulecolor=\color{black!20},
    backgroundcolor=\color{gray!5},
    tabsize=4,
    captionpos=b
}

\title{Report}
\author{Lucas SALAND}
\date{\today}

\begin{document}
\input{title_page.tex}
\tableofcontents
\listoffigures
\listoftables
\section{Introduction}
Communication is crucial in our civilization. There are many ways to communicate and transmit information nowadays. The rise of information technology in the past decades enabled more communication than ever before in many different forms: images, texts, videos, audios\dots Information is encoded in a specific way for each type of information. And even for a same type of media such as images, there exist different formats in which information can be encoded. What can be done when hidden communication is needed on a transmission channel that other might have access to? A first idea could be to use encryption to hide the meaning of the messsage, the presence of the message is known, its meaning is unknown.  A second idea is to hide the message to be transmitted in another piece of content and transmit it without raising suspicions about the modified piece of content. This is called steganography. The original piece of content is called a cover. Once the hidden message has been embedded, it becomes the stego. Steganography is often paired with steganalysis. The goal of steganalysis is to detect whether a message was hidden in a given piece of content. In this project, we were interested in steganography performed on AI-compressed images.\\
There exists many papers on steganography performed on JPEG images but none explored yet steganography on AI-compressed images. Images can be represented in many different spaces: RGB, DCT (JPEG), YCbCr, HSV/HSL... The first step of steganography on images is to chose on which representation of images we want to embbed the message. AI-compressed images have their own representation.\\
Using deep learning for image compression was first introduced in "End-To-End Optimized Image Compression". This paper developed the idea of using convolutional neural network to obtain a representation of images in a latent space. This representation in latent space is the one on which steganography will be performed. Modern steganalysis on images relies on neural network detectors. In this project, we use SRNet to perform classification of images with classes "stego" and "cover".

\section{AI image compression}
\subsection{Autoencoder and latent space}
The idea behind AI image compression is to have a compact representation of images using deep learning. To do so, we can use an autoencoder. The encoder part is used to obtain a representation of images in latent space. The coefficients of this representation is then quantized. We can then reconstruct a quantized image by feeding the quantized latent representation to the decoder part of the autoencoder. The training is done by optimizing the weighted sum of the rate and distortion \autocite{balleEndtoendOptimizedImage2017}.
\begin{figure}[H]
    \centering
    \includegraphics*[width=.6\textwidth]{./img/transform_coding.png}
    \caption[Representation of images]{$x$: uncompressed image, $y$: latent representation of $x$, $\hat{y}$: quantized latent representation of $x$, $\hat{x}$ reconstructed image}
\end{figure}
Compressed images obtained with the autoencoder approach are smoother than the ones obtained with JPEG.
\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{./img/jpeg_ai.png}
    \caption[AI compression vs JPEG]{AI compression vs JPEG compression (End To End Image Compression paper)}
\end{figure}

A pytorch implementation of this idea was provided by the iclr\_17\_compression repository \autocite{LiujiahengIclr_17_compressionEndtoend} available on Github. Nevertheless, no model checkpoint nor training data were provided.


\subsection{Training the model}
The generation of the training data was done using a script provided on the github repository. With this script, 80G of training data are generated. Once the training data has been generated, the training of the model can be started. The model used in all other experiments in this report has been trained over 1590000 steps across 6 epochs. The base models from which all other model in this project are derived from is called ImageCompressor.
\begin{figure}[H]
    \centering
    \includegraphics[width=.8\textwidth]{./img/ImageCompressor.png}
    \caption[ImageCompressor model]{ImageCompressor model}
\end{figure}

\begin{figure}[H]
    \centering
    \includegraphics[width=\textwidth]{img/Original_reconstructed.png}
    \caption[Image uncompressed \& AI compressed]{Input \& output of ImageCompressor model}
\end{figure}

\section{Steganography}
\subsection{Naive method: LSB replacement}
\subsubsection{Least significant bit replacement}
The least significant bit replacement consists in adding or substracting 1 to quantized coefficients of the latent representation with a given probability. We can model the modification as follows:

\begin{itemize}
    \item $c_i: \text{quantized coefficient in the latent space}$
    \item $\mathcal{E}
    _i \sim Categorical_{\{-1,0,1\}},\\
    \ \mathbb{P}(\mathcal{E}_i = -1) = \mathbb{P}(\mathcal{E}_i = 1) = p,\\
    \mathbb{P}(\mathcal{E}_i = 0) = 1-2p$ 
    \item $\hat{C}_i = c_i + \mathcal{E}_i \sim Categorical_{\{c_i-1,\ c_i,\ c_i+1\}}:$ quantized coefficient after modification
\end{itemize}

For each coeffcient $c_i$ we sample a realization $\epsilon_i$ of $\mathcal{E}_i$ and obtain the modified version of this coefficient $\hat{c_i}$ which is a realization of $\hat{C_i}$.\\
The image reconstructed from the original latent representation is called the \textbf{cover} whereas the one reconstructed from the modified latent representation is called the \textbf{stego}.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{./img/naive_insertion.png}
    \caption[Diagram of the probabilities of modification of coefficients]{diagram of the probabilities of modification of coefficients}
    \label{fig:probabilities}
\end{figure}
The insertion rate is given by $H_3(p) = -2p*log_2(p) - (1-2p)log_2(1-2p)$ in bits per coefficient. The size of the message we embbed is given by \[\text{size = number coefficients in latent space * insertion rate}\]
\subsubsection{Implementation}
The insertion is done on the quantized coefficients in latent space. Thus, a new model ImageCompressorSteganography based on ImageCompressor contains the necessary steps to perform the insertion given a probability p (see \autoref{fig:probabilities}). The first version of the LSB modification was implemented using 3 for-loops. Due to low performances of python for-loops, a new implementation was done using pytorch's multinomial method, enabling computations to be performed 30 times faster by taking advantage of GPU's computational power.

\subsection{Side information: quantization error}
The LSB modification is a very basic approach to perform steganography. Its simplicity makes it easy to detect. Every coeffcient in the latent representation has the same probability of modifications. To make it less detectable, we can use the quantization error: the difference between original coefficients and quantized coefficients in latent space. The goal is to give higher probability of modification where the quantization error is important and smaller probabilities where the quantization error is close to zero.  
\subsubsection{Non-uniform probability of modification}
To obtain different probabilities of modification for each coefficient, an optimization problem under constraint must be solved, the unknown is $\lambda$:

\begin{table}[H]
\begin{tabular}{ |c|c|c| }
    \hline
    &  & Comments\\
    \hline
    & $e_i = \text{coef}_i - \text{quantized\_coef}_i$ & quantization error on the i-th coefficient\\ 
    & $c_{i,-1} = 1 + 2e_i$ & cost of -1 modification\\ 
    Notations & $c_{i,0} = 0$ & no penalization\\
    & $c_{i,1} = 1 - 2e_i$ & cost of +1 modification\\
    & $p_{i,k} = \frac{e^{-\lambda c_{i,k}}}{e^{-\lambda c_{i,-1}} + e^{-\lambda c_{i,0}} + e^{-\lambda c_{i,1}}}$ & probability of +k on coef i, k $\in$ \{-1,0,1\}\\
    & $\lambda$ & variable of the problem\\
    \hline
    Constraint & $\displaystyle\sum_{i=1}^{\# coefs}{H_3(p_{i,-1},p_{i,0},p_{i,1})} = M$ & M: size of the message to insert in bits\\
    \hline
    Objective & $\displaystyle\sum_{i=1}^{\# coefs}{\sum_{k=-1}^{1}{p_{i,k}c_{i,k}}}$ & distorsion to minimize \\ 
    \hline
\end{tabular}
\caption[Side information]{Optimization problem to solve}
\end{table}

This problem is solved using an iterative algorithm. The code for this algorithm was kindly provided by Patrick Bas. This code only works with 1-D numpy arrays.

\subsubsection{Implementation}
Since the code for solving the optimization problem is given, we only needed to get the elements to run it: 1D numpy arrays of the cost of +1 and -1 modifications.

\DontPrintSemicolon
\begin{algorithm}[H]
    \SetKwInOut{KwIn}{Notations}
    \caption[Side information algorithm]{Side information}
    \KwIn{\\
    C: latent representation of an image\\
    Q: quantized version of C\\
        QE: quantization error\\
        $\rho_{+1}$: array of costs of +1 modifications\\
        $\rho_{-1}$: array of costs of -1 modifications\\
        $p_{+1}$: array of probabilities of +1 modification\\
        $p_{-1}$: array of probabilities of -1 modification\\
        Q': Q with modified coef w.r.t $p_{-1}$, $p_{+1}$ probabilities\\
        M: size of the message to embbed\\
        N: number of coeffcients in C}
        $Q \gets round(C)$\\
        $QE \gets C - Q$\\
        $QE.flatten()$\\
        $\rho_{+1} \gets 1 + 2QE $\\
        $\rho_{-1} \gets 1 - 2QE $\\
        $p_{+1}, p_{-1} \gets get\_probas(\rho_{+1},\rho_{-1},M,N)$\\
        $Q' \gets modif\_coef(Q,p_{+1},p_{-1})$
    \end{algorithm}

\subsubsection{Modifying the cost}
The third method is similar to the second one. The only difference is how the cost of modification are computed. In this method, there is a non negative cost associated to the +0 modification. This change was driven by curiosity. We were wondering what would be the impact of penalizing the absence of modification.
\begin{table}[H]
\begin{tabular}{ |c|c|c| }
    \hline
    &  & Comments\\
    \hline
    & $e_i = \text{coef}_i - \text{quantized\_coef}_i$ & quantization error on the i-th coefficient\\ 
    & $\textcolor{red}{c_{i,-1} = 1 + e_i}$ & cost of -1 modification\\ 
    Notations & $\textcolor{red}{c_{i,0} = |e_i|}$ & cost of no modification\\
    & $\textcolor{red}{c_{i,1} = 1 - e_i}$ & cost of +1 modification\\
    & $p_{i,k} = \frac{e^{-\lambda c_{i,k}}}{e^{-\lambda c_{i,-1}} + e^{-\lambda c_{i,0}} + e^{-\lambda c_{i,1}}}$ & probability of +k on coef i, k $\in$ \{-1,0,1\}\\
    & $\lambda$ & variable of the problem\\
    \hline
    Constraint & $\displaystyle\sum_{i=1}^{\# coefs}{H_3(p_{i,-1},p_{i,0},p_{i,1})} = M$ & M: size of the message to insert in bits\\
    \hline
    Objective & $\displaystyle\sum_{i=1}^{\# coefs}{\sum_{k=-1}^{1}{p_{i,k}c_{i,k}}}$ & distorsion to minimize \\ 
    \hline
\end{tabular}
\caption[Side information variant]{Variant of the optimization problem}
\end{table}

\section{Steganalysis}
\subsection{JIN SRNet}
JIN SRNet is a deep convolutional neural network whose purpose is to detect if steganography was performed on an image \autocite{liuLosslessImageSteganography2022}. It is pretrained on ImageNet database \autocite{butoraRevisitingPerturbedQuantization2021}. This model can be fine tuned to assess the performances of naive insertion and side information methods. A first idea to compare the 2 methods was to compare the prediction error of JINSRNet on two stego datasets generated with the two methods for the same payload. A second idea is to generate 2 stego datasets with different payload for each method such that the prediction error is the same. 
\subsubsection{Generating cover and stego datasets}
To fine-tune the JINSRNet model, the first step is to generate cover and stego datasets. The original dataset used is BossBase. A dataset of 10 000 grayscaled images saved in pgm format. 

\begin{figure}[H]
    \includegraphics[width=\textwidth]{img/bossbase.png}
    \caption[BossBase]{Images from BossBase dataset}
    \label{fig:bossbase}
\end{figure}

The cover dataset is generated by feeding the 10 000 images from BossBase to ImageCompressor, the images are saved as .pt (pytorch tensors). For stego datasets, several where generated for each method. One dataset is generated per payload and per method used. Taking into consideration that Bossbase, cover and one stego dataset take 90GB of space on disk, it was not possible to store many versions of stego datasets at once. Thus, every time a new stego dataset was generated, the previous one was removed in order to save some space.\\
For every method, the generation of the stego dataset is similar. The only difference is which variant of ImageCompressor model is used. The steps are the following:
\begin{itemize}
    \item read pgm files (original images from BossBase)
    \item convert each file into a tensor as ImageCompressor-based models works with tensors
    \item feed the tensor image to the ImageCompressor-based model corresponding to the method we want to use with the correct payload (ImageCompressorSteganography for LSB, ImageCompressorSteganography\_QE for side information and ImageCompressorSteganography\_QE\_modified\_cost for the variant of side information)
    \item save the generated image as a tensor on disk
\end{itemize}

As ImageCompressor-based models were designed to work on RGB images, it takes as input tensors with three color channels. Thus the grayscale channel of pgm images was duplicated on three channels \autocite{butoraStatisticalModelsImage2017} in order to feed them to each model.\\
Two options where available for saving images on disk:
\begin{enumerate}
    \item Save the latent representation as .pt
    \item Save the reconstructed tensor image as .pt
\end{enumerate}
Option 1 was implemented first, but due to some unkown reason, the tensor saved on disk was different from the original one once it was loaded. This might be a bug from pytorch. This resulted in the appearance of anomalies on the reconstructed images as seen on \autoref{fig:save}. Consequently, option 2 was implemented to have properly reconstructed images.
\begin{figure}[H]
    \includegraphics[width=.49\textwidth]{img/anomalies.png}
    \includegraphics[width=.49\textwidth]{img/correct_img.png}
    \caption[Image reconstructed from tensor saved on disk]{image reconstructed with option 1 vs image with options 2}
    \label{fig:save}
\end{figure}

\subsubsection{Fine-tuning the pretrained model}
Once the datasets are generated. We can fine-tune JINSRNet.
Training script and pretrained model were kindly provided by Jan Butora. Some adjustment were needed in order to load the training data as the original script loaded jpeg files. The class loading the data is called a retriever. We implemented a retriever that works with .pt files (pytorch tensors). The images saved as pytorch tensors are loaded and converted into numpy arrays. To convert pytorch images into numpy images there is two different methods. The first one consists in using the ToPILImage() function of pytorch which converts a pytorch tensor into a PIL image which we can then convert into a numpy array. The second method consists in permuting axis of the tensor to fit numpy convention for representation of images and then converting the tensor into a numpy array by using numpy() function of pytorch Tensor class. As we can see on \autoref{tab:torch2np}, the method of permuting axis and converting to NumPy using numpy() function is about 10 times faster than the other method. Thus this method is the one used for tensor to numpy array conversion.\\

\begin{lstlisting}[caption={Conversion of pytorch tensors into numpy images}, label={lst:example}]
to_pil = ToPILImage()
# bad performance
img_numpy = np.array(to_pil(img_pytorch[0]))

# good performance
img_numpy = img_pytorch[0].permute(1,2,0).cpu().numpy() 
\end{lstlisting}

\begin{table}[H]
    \centering
    \begin{tabular}{|c|c|}
        \hline
        ToPIL & numpy()\\
        \hline
        $5.15\ ms\ \pm\ 238 \mu s$  & $523 \mu s\ \pm\ 18.7 \mu s  $\\
        \hline
    \end{tabular}
    \caption[Performances comparison of tensor to numpy conversion]{Performances comparison of tensor to numpy conversion}
    \label{tab:torch2np}
\end{table}

\begin{table}[H]
    \centering
\begin{tabular}{|c|c|c|}
    \hline
    Axis & Pytorch & Numpy \\
    \hline
    0 & batch dimension & height \\
    \hline
    1 & channel & width\\
    \hline
    2 & height & channel\\
    \hline
    3 & width & $\emptyset$\\
    \hline
\end{tabular}    
\caption[Difference of image representation between NumPy and Pytorch]{Difference of image representation between NumPy and Pytorch}
\end{table}
The first fine-tuning training were done for the LSB replacement method. A stego dataset needs to be generated for each insertion rate. The first training was performed for an insertion rate of 1.5 bpc (bits per coefficient). Which is the highest insertion rate possible. At this rate, it is possible to draw distinction between cover and stego images just by looking at them. This training was done to make sure that JINSRnet could easily distinguish them. Once the first training was performed, the insertion rate was progressively decreased. The metric of interest was the prediction error on validation set. The goal was to find, for the LSB replacement method, an insertion rate such that the prediction error would be between 10\% ad 20\% in order to have some margin to see the improvment in performance with the side information method. This was done with the idea of comparing methods for a given insertion rate. We will see in the next section this comparison was not possible. Therefore, the other way of comparing methods has been prefered: finding different insertion rates for which all methods have similar prediction error.

\subsection{Results}
Fine-tuning for LSB replacement was performed with a pretrained version of JINSRNet provided by Jan Butora for embedding rate from 1.5 bpc to 0.002 bpc. After that, the checkpoint of SRNet from the 0.002 bpc training  was used for other embedding rates and methods to have faster convergence.
\begin{figure}[H]
    \includegraphics[width=\textwidth]{img/val_pe_all.png}
    \caption[Steganalysis results]{Prediction error on validation set for all methods and 
    different embedding rates}
    \label{fig:results}
\end{figure}

\subsubsection{LSB replacement}
\begin{figure}[H]
    \includegraphics[width=\textwidth]{img/lsb_results.png}
    \caption[LSB replacement result]{LSB replacement results}
    \label{fig:lsb_results}
\end{figure}
The difficulty in the fine-tunning process was to find embedding rates so that drawing distinction between cover and stego would not be too hard (50\% prediction error) nor too easy (0\% prediction error). The embedding rate of 0.003 bpc was the first one for which we could obtain a prediction error in the 5\% - 20\% prediction error range. The weights of the model obtained from this training were then used for other training with lower embedding rates. We can see that there has been two trainings performed for an embedding rate of 0.001 bpc (see gray and dark blue curves on \autoref{fig:lsb_results}). The gray curve was the training performed with the first pretrained model of JINSRNet, the model could not distinguish cover and stego images as the prediction error on validation set was 50\%. Using the fine-tuned version obtained from the 0.003 bpc training, we obtained the blue curve with a prediction error between 15\% and 20\%. The results from LSB replacement serves as a baseline for comparison with other methods.

\subsubsection{Side information methods}
\begin{figure}[H]
    \includegraphics[width=\textwidth]{img/side_inf_results.png}
    \caption[Side information methods results]{Prediction error on validationset for both side information methods}
    \label{fig:side_inf_results}
\end{figure}
Side information-based methods were able to embbed far more information before becoming detectable. During this trainings, we realized that we would not find a embedding rate such that we could have both side information and LSB replacement in the (0\%,50\%) range. Either the LSB stego would be too easy to detect or the side information stego would be too hard to detect. Consequently, we decided to find an embedding rate for which the prediction errors are similar for the different methods.

\subsubsection{Comparison}
\begin{figure}[H]
    \includegraphics[width=\textwidth]{img/results_comparison.png}
    \caption[Comparative results]{Comparison between the 3 methods}
    \label{fig:results_comparison}
\end{figure}
These three curves were obtained using the same version of JINSRNet (checkpoint from the 0.003 bpc training). As we can see, we could obtain similar prediction errors for the three methods. We observe that side information allows an embedding rate approximatively 60 times higher than LSB method.

\section{Conclusion}
This project has been a first look on steganography performed on images compressed by AI. Embedding information in the latent representation of images obtained through encoder network was not studied before and we obtained baseline results for different methods: LSB replacement, side information and its variant. There are many perspectives for this project. A comparison with JPEG steganography  would help to see the benefits and inconvenients of steganography on AI-compressed images. During this project, steganography was only performed on grayscale images as we used BossBase dataset. We could work on RGB images as the autoencoder used for image compression works with RGB images. Finally, to obtain better results, running tests for the different methods instead of just usinf the prediction error on validation set would have been better but it has not been done due to a lack of time.

\printbibliography
\end{document}